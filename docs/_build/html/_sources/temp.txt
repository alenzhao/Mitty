Creating distributables
=======================

    sudo apt-get install python-dev  # Is common for a lot
    sudo pip install wheel


    sudo apt-get install zlib1g-dev  # This is needed for pysam

    sudo apt-get install python-numpy  # This is much less painful than letting pip compile it
    sudo apt-get install python-scipy  # This is much less painful than letting pip compile it





pysam
-----


    sudo apt-get install zlib1g-dev
    git clone https://github.com/pysam-developers/pysam.git
    sudo pip install .
    pip wheel pysam


numpy
-----
    sudo apt-get install build-essential python-dev swig gfortran python-nose
    download numpy source
    BLAS=None LAPACK=None ATLAS=None python setup.py build
    pip wheel numpy


Handling PyVCF
--------------
The problem with PyVCF is that

Under ``vcf/__init__.py`` change VERSION to 0.7.0.

``pip wheel .`` copy this to the devpi server. Then require this in setup.py of Mitty





De Novo variant collision detection
-----------------------------------

When Mitty places de novo variants it prevents collisions with earlier variants by using a mask. I ended up going with
bitarray because it gave the best space/time tradeoff.


Speed optimizing denovo.py
--------------------------

Initially I was using scipy.sparse.lil_matrix for the collision mask, because I figured that this was the best way to economize on
space. I found, however, by simple profiling, that lil was taking what I considered to be a lot of time. I tried various other
sparse matrix types but lil was the fastest. I was especially bothered by the overhead of the lil __getitem__ call which
I thought was taking way too much cumulative time.

I was afraid to use regular arrays (regular numpy arrays gave a 5x speed up compared to sparse arrays) because I thought
this would not scale spacewise, because a whole genome simulation would take about 7 GB for the mask alone. Then I tried
bitarray. This turned out to be really fast though it does take some time during initialization.

Going from scipy.sparse to bitarray gave a 7x speed boost, knocking down execution time from 70s to 10s. Very interestingly,
when I replaced the `Variant` data type (which was a `named_tuple`) with a ctypes struct class the total time was knocked
down to 3s. I was shocked that a data type could be so inefficient, but it is used everywhere, and all the time, so
it is logical that any inefficiency here creates such a great effect.

So overall, for sprinkling about 130000 SNPs on chromosome 11, denovo.py went from 70s to 3s by some simple alterations.

Profile results: chr11 130000 SNPs
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
The following profile runs demonstrate why I ended up using `bitarray` for the collision detection mask

typical command line::

    python -m cProfile -o bitarray_stats.bin ../mitty/denovo.py  --wg ../examples/Human/Out/chr_11.h5  --vcf test.vcf.gz  --param_file ../examples/denovo/snp.json  --master_seed=1 -v
    DEBUG:__main__:Reference file ../examples/Human/Out/chr_11.h5
    DEBUG:mitty.Plugins.variants.snp_plugin:Used master seed to generate seeds 90950894, 39770206, 70599635, 88188254
    DEBUG:__main__:131015 of 131131 variants placed
    DEBUG:variation:Sorting /var/folders/s_/bhgzsrbj7cj220_s1cnpzgvm0000gn/T/tmpyenywa.vcf to test.vcf
    DEBUG:variation:Compressing and indexing test.vcf to test.vcf.gz

sparse matrix::

    In [53]: p = pstats.Stats('sparsearray_stats.bin')
    In [54]: p.strip_dirs().sort_stats('tottime').print_stats(30)
    Thu Aug  7 08:11:20 2014    sparsearray_stats.bin

             49637097 function calls (49636390 primitive calls) in 73.646 seconds

       Ordered by: internal time
       List reduced from 1047 to 30 due to restriction <30>

       ncalls  tottime  percall  cumtime  percall filename:lineno(function)
       655126    7.340    0.000   18.639    0.000 stride_tricks.py:36(broadcast_arrays)
            1    6.791    6.791   65.445   65.445 denovo.py:120(arbitrate_variant_collisions)
       917388    5.115    0.000    8.444    0.000 stride_tricks.py:22(as_strided)
      3407329    4.716    0.000    4.716    0.000 {numpy.core.multiarray.array}
       458694    4.112    0.000   22.274    0.000 sputils.py:329(_index_to_arrays)
       262262    3.974    0.000    3.974    0.000 {scipy.sparse._csparsetools.lil_fancy_get}
       196432    2.690    0.000    2.690    0.000 {scipy.sparse._csparsetools.lil_fancy_set}
       917388    2.436    0.000    3.810    0.000 sputils.py:310(_check_boolean)
     10683970    2.344    0.000    2.644    0.000 {isinstance}
       458694    2.230    0.000    5.354    0.000 sputils.py:244(_unpack_index)
       262262    2.170    0.000   36.775    0.000 lil.py:228(__getitem__)
       196432    1.922    0.000   21.189    0.000 lil.py:270(__setitem__)
            3    1.759    0.586    1.759    0.586 {method 'rand' of 'mtrand.RandomState' objects}
       262263    1.759    0.000    8.985    0.000 lil.py:86(__init__)
      2948597    1.525    0.000    5.519    0.000 numeric.py:392(asarray)
       524526    1.453    0.000    2.280    0.000 fromnumeric.py:2412(ndim)
       524548    1.449    0.000    1.449    0.000 {numpy.core.multiarray.empty}
       458694    1.146    0.000    3.341    0.000 shape_base.py:8(atleast_1d)
       458694    0.956    0.000    0.956    0.000 {scipy.sparse._csparsetools.prepare_index_for_memoryview}
       262263    0.913    0.000    4.245    0.000 sputils.py:204(isshape)
       458694    0.867    0.000    0.867    0.000 {method 'reshape' of 'numpy.ndarray' objects}
       458694    0.815    0.000    0.861    0.000 sputils.py:272(_check_ellipsis)
      2489903    0.806    0.000    1.426    0.000 base.py:861(isspmatrix)
       458694    0.795    0.000    0.795    0.000 {numpy.core.multiarray.arange}
            1    0.789    0.789    0.789    0.789 {posix.waitpid}
    7015738/7015606    0.696    0.000    0.696    0.000 {len}
       655075    0.599    0.000    0.599    0.000 collections.py:54(__setitem__)
       262263    0.575    0.000    0.607    0.000 lil.py:132(set_shape)
            2    0.562    0.281    3.391    1.695 snp_plugin.py:51(variant_generator)
       262262    0.551    0.000    0.690    0.000 lil.py:181(getnnz)

numpy array::

    In [51]: p = pstats.Stats('numpyarray_stats.bin')
    In [52]: p.strip_dirs().sort_stats('tottime').print_stats(30)
    Thu Aug  7 08:08:02 2014    numpyarray_stats.bin

             4222136 function calls (4221429 primitive calls) in 10.668 seconds

       Ordered by: internal time
       List reduced from 1015 to 30 due to restriction <30>

       ncalls  tottime  percall  cumtime  percall filename:lineno(function)
            1    2.501    2.501    2.670    2.670 denovo.py:120(arbitrate_variant_collisions)
            3    1.764    0.588    1.764    0.588 {method 'rand' of 'mtrand.RandomState' objects}
            1    0.787    0.787    0.787    0.787 {posix.waitpid}
            2    0.575    0.288    3.407    1.704 snp_plugin.py:51(variant_generator)
       655075    0.566    0.000    0.566    0.000 collections.py:54(__setitem__)
            3    0.536    0.179    0.536    0.179 {method 'nonzero' of 'numpy.ndarray' objects}
       131015    0.509    0.000    1.550    0.000 _abcoll.py:526(update)
       131015    0.406    0.000    2.099    0.000 collections.py:38(__init__)
            1    0.364    0.364    3.377    3.377 variation.py:77(vcf_save)
            1    0.335    0.335    0.335    0.335 {method 'read' of 'h5py.h5d.DatasetID' objects}
       131015    0.221    0.000    2.375    0.000 <string>:24(_asdict)
       131193    0.202    0.000    0.202    0.000 {method 'format' of 'str' objects}
       131015    0.180    0.000    0.287    0.000 abc.py:128(__instancecheck__)
       262262    0.169    0.000    0.169    0.000 {numpy.core.multiarray.count_nonzero}
       393058    0.143    0.000    0.143    0.000 _weakrefset.py:70(__contains__)
            1    0.139    0.139    0.139    0.139 {pysam.ctabix.tabix_compress}
       131029    0.128    0.000    0.128    0.000 {map}
       262157    0.126    0.000    0.126    0.000 {built-in method __new__ of type object at 0x100183140}
       131020    0.121    0.000    0.121    0.000 {zip}
       131015    0.111    0.000    0.357    0.000 <string>:28(_replace)
       131057    0.084    0.000    0.084    0.000 {hasattr}
       131021    0.079    0.000    0.079    0.000 {method 'write' of 'file' objects}
    131027/131026    0.076    0.000    0.133    0.000 abc.py:148(__subclasscheck__)
       132944    0.071    0.000    0.358    0.000 {isinstance}
       131015    0.064    0.000    0.117    0.000 <string>:12(_make)
          2/1    0.061    0.030   10.567   10.567 denovo.py:69(<module>)
            1    0.050    0.050    0.050    0.050 {pysam.ctabix.tabix_index}
    528191/528059    0.042    0.000    0.042    0.000 {len}
       131131    0.040    0.000    0.125    0.000 <string>:8(__new__)
       131530    0.020    0.000    0.020    0.000 {getattr}



bitarray::

    In [55]: p = pstats.Stats('bitarray_stats.bin')
    In [56]: p.strip_dirs().sort_stats('tottime').print_stats(30)
    Thu Aug  7 08:16:50 2014    bitarray_stats.bin

             4222178 function calls (4221471 primitive calls) in 10.629 seconds

       Ordered by: internal time
       List reduced from 1015 to 30 due to restriction <30>

       ncalls  tottime  percall  cumtime  percall filename:lineno(function)
            3    1.785    0.595    1.785    0.595 {method 'rand' of 'mtrand.RandomState' objects}
            1    1.775    1.775    1.793    1.793 denovo.py:123(arbitrate_variant_collisions)
            1    0.787    0.787    0.787    0.787 {posix.waitpid}
            1    0.662    0.662    0.662    0.662 denovo.py:85(initialize_mask)
       655075    0.593    0.000    0.593    0.000 collections.py:54(__setitem__)
            2    0.578    0.289    3.406    1.703 snp_plugin.py:51(variant_generator)
       131015    0.533    0.000    1.622    0.000 _abcoll.py:526(update)
            3    0.524    0.175    0.524    0.175 {method 'nonzero' of 'numpy.ndarray' objects}
       131015    0.438    0.000    2.206    0.000 collections.py:38(__init__)
            1    0.387    0.387    3.561    3.561 variation.py:77(vcf_save)
            1    0.336    0.336    0.336    0.336 {method 'read' of 'h5py.h5d.DatasetID' objects}
       131015    0.236    0.000    2.500    0.000 <string>:24(_asdict)
       131194    0.218    0.000    0.218    0.000 {method 'format' of 'str' objects}
       131015    0.188    0.000    0.298    0.000 abc.py:128(__instancecheck__)
       393058    0.147    0.000    0.147    0.000 _weakrefset.py:70(__contains__)
            1    0.145    0.145    0.145    0.145 {pysam.ctabix.tabix_compress}
       131029    0.135    0.000    0.135    0.000 {map}
       131015    0.119    0.000    0.374    0.000 <string>:28(_replace)
       131020    0.119    0.000    0.119    0.000 {zip}
       262157    0.118    0.000    0.118    0.000 {built-in method __new__ of type object at 0x100183140}
       131057    0.089    0.000    0.089    0.000 {hasattr}
       131021    0.082    0.000    0.082    0.000 {method 'write' of 'file' objects}
    131027/131026    0.078    0.000    0.137    0.000 abc.py:148(__subclasscheck__)
       132950    0.075    0.000    0.373    0.000 {isinstance}
       131015    0.067    0.000    0.120    0.000 <string>:12(_make)
          2/1    0.062    0.031   10.532   10.532 denovo.py:69(<module>)
            1    0.052    0.052    0.052    0.052 {pysam.ctabix.tabix_index}
    528191/528059    0.042    0.000    0.042    0.000 {len}
       131131    0.039    0.000    0.116    0.000 <string>:8(__new__)
       131530    0.022    0.000    0.022    0.000 {getattr}


bitarray with ctypes class for Variation::

    In [45]: p = pstats.Stats('bitarray_stats.bin')
    In [46]: p.strip_dirs().sort_stats('tottime').print_stats(30)
    Fri Aug  8 06:18:49 2014    bitarray_stats.bin

             420785 function calls (420089 primitive calls) in 3.633 seconds

       Ordered by: internal time
       List reduced from 923 to 30 due to restriction <30>

       ncalls  tottime  percall  cumtime  percall filename:lineno(function)
            1    0.884    0.884    0.884    0.884 {posix.waitpid}
            1    0.657    0.657    0.659    0.659 denovo.py:84(initialize_mask)
            2    0.594    0.297    1.098    0.549 snp_plugin.py:51(variant_generator)
            1    0.415    0.415    0.415    0.415 {method 'read' of 'h5py.h5d.DatasetID' objects}
            1    0.289    0.289    0.306    0.306 denovo.py:114(arbitrate_variant_collisions)
            1    0.178    0.178    0.235    0.235 variation.py:103(vcf_save)
            1    0.147    0.147    0.147    0.147 {pysam.ctabix.tabix_compress}
            1    0.069    0.069    0.069    0.069 {pysam.ctabix.tabix_index}
            5    0.064    0.013    0.064    0.013 {zip}
       131115    0.057    0.000    0.057    0.000 {method 'write' of 'file' objects}
          2/1    0.055    0.027    3.541    3.541 denovo.py:69(<module>)
            3    0.021    0.007    0.021    0.007 {open}
       262218    0.017    0.000    0.017    0.000 {method 'any' of 'bitarray._bitarray' objects}
            1    0.015    0.015    0.015    0.015 {method 'poisson' of 'mtrand.RandomState' objects}
            3    0.014    0.005    0.087    0.029 __init__.py:10(<module>)
            1    0.010    0.010    1.415    1.415 denovo.py:150(add_variant_model_to_genome)
            9    0.010    0.001    0.058    0.006 __init__.py:1(<module>)
            2    0.006    0.003    0.006    0.003 {method 'read' of 'file' objects}
            1    0.005    0.005    0.006    0.006 __init__.py:88(<module>)
            2    0.005    0.002    0.006    0.003 {__import__}
            1    0.004    0.004    3.451    3.451 denovo.py:195(main)
          273    0.003    0.000    0.004    0.000 function_base.py:2945(add_newdoc)
            2    0.003    0.002    0.034    0.017 variation.py:6(<module>)
            1    0.003    0.003    0.004    0.004 polynomial.py:55(<module>)
            5    0.003    0.001    0.004    0.001 collections.py:288(namedtuple)
            7    0.003    0.000    0.003    0.000 {method 'sub' of '_sre.SRE_Pattern' objects}
       114/42    0.003    0.000    0.007    0.000 sre_parse.py:379(_parse)
            1    0.002    0.002    0.003    0.003 hermite.py:59(<module>)
            1    0.002    0.002    0.007    0.007 util.py:11(zygosity)
            1    0.002    0.002    0.003    0.003 laguerre.py:59(<module>)



mutate.py
---------
Internally, Mitty stores each variant as a group of operations

(type, zygosity, footprint)
()



The reference is assumed to be haploid (we always use copy 1)

Mitty stores the actual generated variant in a systematic format in a hdf5 file. Conceptually, each variant is stored
as follows:

   _ type name
  /
(type, zygosity, footprint, )
        \            \
         \            \_ list of variant description tuples
          \
              0 -> no variant (due to arbitration, see below)
              1 -> variant on copy 1
              2 -> variant on copy 2
              3 -> variant on both copies

Most commonly, there is only one element in the list of variant descriptions and this corresponds exactly with a VCF
file entry. Complicated variants are expressed as a sequence of insertions and deletions.

Each variant model returns a variant file of proposed variants in this format. Mitty then arbitrates between all the
variants to make sure they don't clash.

Variant types:

SNP             - footprint is 1
Insert          - footprint is 0
Delete          - footprint is N
Inversion       - footprint is N
Repeat          - footprint is N
Translocation   - foorprint is N

Mitty writes out variants in VCF format (using the variant2vcf tool).

Each model should have a .variant method that is passed the reference genome data and any general and specific
parameters it needs. Each model's .variant method is called in turn and it fills out the variant data structure
(on an hdf5 file, due to the potential size of the data) and returns it to mutate.py

mutate.py is responsible for arbitrating between variants that clash by using a genome-wide mask.



Passing whole genome file to mutation plugins
---------------------------------------------
This allows plugins to do non-local things, like translocations, which they would not be able to do if they only recieved
a sequence.



Choice to output a mutated sequence as a whole
----------------------------------------------
VCF files (especially with the literal phase information as used by Mitty) form a complete description of a genome (in the form of diffs to the reference, haploid, sequences). However, for the purposes of taking reads the whole mutated genome is written out explicitly. I chose this approach as it ended up being simpler than implementing an algorithm for generating reads on the fly based on a VCF file. In the future the code may be modified to do on the fly generation.


Random number seeds
-------------------
All stock plugins employ explicit random number seeds. Random number generators for different parameters of the simulation are decoupled (independent) from each other and each takes its own seed (Though all plugins can take a single master seed which they use to generate the required number of individual seeds). This is an important design choice that allows exact reproducibility of simulations and allows us to avoid couplings between parameters which might otherwise crop up if the same random number generator was used for all the simulation variables.


vcf2seq - why we store VCF details
----------------------------------
In some use cases [#localreads]_ we need to know which parts of the mutated genome are mutated. For this reason we store the positions of mutations (in `/variants/pos/`) and the details of the variant (`/variants/codes/`).

.. [#localreads] The `reads.py` program's `localreads` option uses this, for example, to generate reads from only the insertions.



Running tests
-------------

Running all tests::

    nosetests -v


Including the few doctests there are::

    nosetests mitty --with-doctest -v

Including specific doctests::

    nosetests mitty/Plugins/Mutation --with-doctest -v

Running specific tests::

    nosetests tests.vcf2seq_test:test_assemble_sequences_hetero_same_locus_del -v

Running with coverage::

    nosetests --with-coverage --cover-package=mitty


Profiling the code
------------------

::

    python -m cProfile -o denovostats.bin ../mitty/denovo.py  --wg ../examples/mutate/Out/chimera.h5  --vcf test.vcf.gz  --param_file ../examples/denovo/snp.json -v --master_seed=1

    import pstats
    p = pstats.Stats('denovostats.bin')
    p.strip_dirs().sort_stats('cumulative').print_stats(10)


Generating documentation
------------------------

`sphinx-apidoc mitty/ -o docs` from the root directory




Notes:

1) There are several example shell scripts and parameter files under the `examples` directory

2) Each script has detailed help information that can be accessed using the `-h` option or by simply calling the script
with no options

Population
----------

Roadmap:

* Rework crossover model to match that in text book (current model does not correctly reflect effects on copies
* [DONE] Load reference only once and keep in memory - perhaps give warnings if genome too big for machine and fallback to a
 slower load on demand model. This may mean writing a new class to handle genomes (like we did for variants)
* [DONE] Don't keep population in memory - save as we go and remove to keep memory consumption low and to have partial
 results in case of an abort.
* Finalize .json format for lineage and save that every generation
* [DONE] Profile after optimizing reference loading - if needed get rid of bit mask and use a sorted list for genomes -
implement collision detection based on the sorted vcf - this may be slightly slower than a bit mask, or may be not, if
we have to repeatedly instantiate masks. This will certainly use less memory


The internal structure of an attached pair of chromosomes is a list of tuples of the form:

(start, stop, REF, ALT, zygosity)

The module implements the following useful population functions and their supporting functions

crossover(g1, rng, params) -> g2  simulating cross over between copies of chromosomes
fertilization(g1, g2, rng)   -> g3  simulating creation of a child from parents
denovo(g1, ref, rng, params)  -> g3  the only function that requires the original seq - generates denovo mutations

The module implements and uses the following utility functions

parse_vcf(vcf_reader)  -> g1 read in a VCF file and convert it to out haploid genome format
vcf2chrom(vcf_reader)  -> c1 read in one chromosome from a VCF file
write_to_vcf(fname, g1) write the data to a compressed, indexed VCF file

Internally, the only operation that violates sorting order is denovo, so this uses a blist.sortedlist. For everything
else we use a plain Python list as we only append items (and that is O(1) for a list)




get_rngs(seed)  ->  rng  return a list of random number generators that are used by the different functions

The internal genome format is a simple list of tuples almost corresponding to the VCF

(start, stop, REF, ALT)

The following worker functions operate on single copies of chromosomes

merge(c1, c2) -> c3  merge the descriptions of the two chromosomes
                     This figures out any zygosity mutations. The output is sorted and is of the VCF format
                    (POS, POS1, REF, ALT, HET) We only need this when saving back to VCF



Though we could have written a class called genome, I prefer to write in as functional a style as possible for better
code quality.



vcf2reads
---------

Note:
Expanding the variant sequence takes a bunch of memory because we need 14 bytes per base:

1 byte - forward seq
1 byte - complement seq
4 bytes - pos array  (needed for POS)
4 bytes - diff pos array (needed for CIGAR)
4 bytes - offset array (needed for offset for reads deep in inserts)
-
14 bytes

For this reason we adopt a just in time expansion where by we feed chunks of the variant sequence to the read plugin.
The smaller the chunk size the less extra memory is needed but the chunk computation has an overhead. In general, you
should make the chunk size as large as you can given your memory keeping in mind that each base takes 14 bytes of space
when the variant sequence is expanded.


Algorithm:

1. Read plugin gives us a list of read + template positions (sorted by position along the mutated sequence).
2. We start at the beginning of the reference sequence
3. The read reference is the reference sequence
4. If the template end is before the next variant position:
   1. take reads, repeat 4.
5. If the template end crosses the next variant position:
   1. If read reference is the reference sequence, start an alt sequence,
      otherwise clip existing alt sequence (and pos_array)
   2. Expand the variant, add it to alt seq
   3. Repeat 2 as needed to go past template
   4. Goto 4
6. Repeat all this until reads are exhausted


Roadmap

1. Rewrite to use only reference and VCF file to generate reads
2. Think about how to separate out plugin from main code etc.
3. Make corruption plugin, read plugin separate?


1. The quality scores are in Phred scale (as specified in the SAM spec)
2. We supply the prefix of output file name in the parameter file . Say we set this as sim_reads.
   The perfect reads will be saved to sim_reads.bam (or sim_reads.fastq). If we ask for corrupted reads
   we will get the corrupted reads in the file sim_reads_c.fastq.
   A text sidecar file sim_reads.info will always be saved with simulation parameters.

3 *** Can probably refactor the whole file for better readability **
  *** see if we can write shorter functions, see if we can reduce the number of parameters/bundle them ***
  *** further efficiency gains will probably be minimal - the bottle neck function has been cythonized ***






Generating mutations
--------------------




Read the docs
=============
For further details both on how to use Mitty as well as how to extend it for your custom uses please read the documents.





The program `denovo.py` makes use of variant plugins to sprinkle variants on the reference genome and produce a VCF file
that corresponds to a sample.





Mitty can generate VCF files that indicate mutations with respect to a reference genome. This is done via




                    mutation
                   parameters
                       |
                       V
                    --------
                   |        |----> VCF, VCF.gz, VCF.gz.tbi
       ref seq --->| mutate |
                   |        |----> side car file with sim params
                    --------

Given a set of mutation instructions we can use `mutate.py` to generate a VCF file. For further processing `mutate.py`
compresses the VCF file using `bgzip` and indexes it using `tabix`.


                    ---------
       ref seq --->|         |---> seq_0, seq_1, ... (depending on requested ploidy)
                   | vcf2seq |
       VCF.gz  --->|         |---> pos file
                    ---------

Using the `vcf2seq` tool we can write out the mutations indicated by VCF into a complete mutated sequence saved as a
set of .smalla files. The number of .smalla files depends on the ploidy we request.
We also save a `pos` file which is used by `reads.py` (see below) for writing correct CIGAR strings for each read.


                     read
                   parameters
                       |
                       V
          seq_0     --------
          seq_1    |        |----> corrupted ("real") reads (BAM/FASTQ) if requested.
           ... --->|        |
                   | reads  |----> ideal reads (BAM/FASTQ)
          pos_0 -->|        |
          pos_1    |        |----> side car file with sim params
           ...      --------

The `reads` tool enables us to take a sequence and generate simulated reads from it. The reads can
       simulate various error and property profiles of different sequencers. Each read carries, in its qname field,
       a read serial number and POS and CIGAR strings that can be used to recreate perfect alignments of the reads to
       the original reference. This information is useful for diagnosing the performance of aligners and variant
       callers.


                    ----------
                   |          |
          BAM  --->|  cheata  |---> BAM file with perfect alignments
                   |          |
                    ----------

The `cheata` tool takes a simulated BAM file generated by `reads.py` and uses the POS and CIGAR information stored in
the qname field to generate a perfectly aligned BAM file.


De Novo Variation parameter file
================================
The format is ::

    {
        "variant_models": [  # The order in which we place models indicates their priority
            {
                "model_name": {
                    "param1": v1,
                    "param2": v2
                }
            },
            {
                "model_name": {   # We can repeat a model
                    "param1": v1,
                    "param2": v2
                }
            },
        ]
    }


    {
        "variant_models": [
            {
                "snp": {
                    "chromosome": [3],
                    "phet": 0.0,
                    "p": 0.01,
                    "base_loc_rng_seed": 1,
                    "base_sub_rng_seed": 2,
                    "het_rng_seed": 3,
                    "copy_rng_seed": 4
                }
            },
            {
                "snp": {
                    "chromosome": [1,2],
                    "model": "snp",
                    "phet": 0.5,
                    "p": 0.002,
                    "poisson_rng_seed": 5,
                    "base_sub_rng_seed": 6,
                    "het_rng_seed": 7,
                    "copy_rng_seed": 8
                }
            },
            {
                "insert": {
                    "chromosome": [1],
                    "phet": 0.5,
                    "p": 0.002,
                    "ins_len_lo": 10,
                    "ins_len_hi": 100,
                    "ins_loc_rng_seed": 9,
                    "ins_len_rng_seed": 10,
                    "base_sel_rng_seed": 11,
                    "het_rng_seed": 12,
                    "copy_rng_seed": 13
                }
            },
            {
                "chromosome": [1],
                "model": "delete",
                "phet": 0.5,
                "p": 0.002,
                "del_len_lo": 10,
                "del_len_hi": 100,
                "del_loc_rng_seed": 14,
                "del_len_rng_seed": 15,
                "het_rng_seed": 16,
                "copy_rng_seed": 17
            },
            {
                "chromosome": [1],
                "model": "inversion",
                "phet": 0.5,
                "p": 0.002,
                "inv_len_lo": 10,
                "inv_len_hi": 100,
                "inv_loc_rng_seed": 18,
                "inv_len_rng_seed": 19,
                "het_rng_seed": 20,
                "copy_rng_seed": 21
            }

        ]
    }








Mitty on the commandline
========================


Generating simulated variations
===============================


Converta
--------
We use converta to reorganize sequence data in .fasta files so that Mitty's routines can use them. (Dev note: basically,
by stripping out the header and newlines from the .fasta file the .smalla file can be easily used as a disk mapped
array - via mmap - so we can handle large sequences without loading it into memory all at once)

    >>> shell('python converta.py Data/porcine_circovirus.fa README-DATA/porcine_circovirus')
    >>> with open('README-DATA/porcine_circovirus_0.smalla','r') as f: print f.read()
    ATGACGTATCCAAGGAGGCGTTACCGGAGAAGAAGACACCGCCCCCGCAGCCATCTTGGCCAGATCCTCCGCCGCCGCCCCTGGCTCGTCCACCCCCGCCACCGTTACCGCTGGAGAAGGAAAAACGGCATCTTCAACACCCGCCTCTCCCGCACCTTCGGATATACTATCAAGCGAACCACAGTCAAAACGCCCTCCTGGGCGGTGGACATGATGAGATTCAATATTAATGACTTTCTTCCCCCAGGAGGGGGCTCAAACCCCCGCTCTGTGCCCTTTGAATACTACAGAATAAGAAAGGTTAAGGTTGAATTCTGGCCCTGCTCCCCGATCACCCAGGGTGACAGGGGAGTGGGCTCCAGTGCTGTTATTCTAGATGATAACTTTGTAACAAAGGCCACAGCCCTCACCTATGACCCCTATGTAAACTACTCCTCCCGCCATACCATAACCCAGCCCTTCTCCTACCACTCCCGCTACTTTACCCCCAAACCTGTCCTAGATTCCACTATTGATTACTTCCAACCAAACAACAAAAGAAATCAGCTGTGGCTGAGACTACAAACTGCTGGAAATGTAGACCACGTAGGCCTCGGCACTGCGTTCGAAAACAGTATATACGACCAGGAATACAATATCCGTGTAACCATGTATGTACAATTCAGAGAATTTAATCTTAAAGACCCCCCACTTAACCCTTAG
    >>> with open('README-DATA/porcine_circovirus_0.smalla.heada','r') as f: print f.read()
    gi|52547303|gb|AY735451.1| Porcine circovirus isolate Hebei capsid protein gene, complete cds
    702

Mutate
------
We use mutate, in combination with a mutation parameter file, to generate a VCF file. The `-v` flag causes `mutate.py` to
give a running commentary as it works, which is useful to see if everything is going well.

We will start with a simple experiment where we insert a few SNPs into the porcine circovirus sequence

    >>> import json
    >>> json.dump(
    ... {
    ...      "input smalla file": "README-DATA/porcine_circovirus_0.smalla",
    ...      "output vcf file": "README-DATA/variants.vcf",
    ...      "chromosome": "1",
    ...      "mutations": {
    ...          "snp": {
    ...              "model": "snp",
    ...              "start_snps_frac": 0.1,
    ...              "stop_snps_frac":  0.3,
    ...              "phet": 0.5,
    ...              "p": 0.01,
    ...              "het_rng_seed":3,
    ...              "strand_rng_seed": 4,
    ...              "poisson_rng_seed": 1,
    ...              "base_sub_rng_seed": 2
    ...          }
    ...      }
    ...  }, open('README-DATA/mutations1.json','w'), indent=2)
    >>> shell('python mutate.py --paramfile=README-DATA/mutations1.json  -v')

(For a detailed description of the stock plugin parameters you can run the plugin as a script with the `explain` command,
e.g. `python Plugins/Mutation/insert_plugin.py explain`).

You should see something like:

    DEBUG:__main__:Input sequence: README-DATA/porcine_circovirus_0.smalla
    DEBUG:__main__:Input sequence has 702 bases
    DEBUG:__main__:Output file name: README-DATA/variants.vcf
    DEBUG:__main__:100% done
    DEBUG:__main__:Generated 1 snps
    DEBUG:__main__:Compressing and indexing VCF file

You can take a look at the generated VCF file:

    >>> with open('README-DATA/variants.vcf','r') as f: print f.read()  # doctest: +ELLIPSIS, +NORMALIZE_WHITESPACE
    ##fileformat=VCFv4.1
    ##fileDate=...
    ##source=...
    ##reference=porcine_circovirus_0.smalla
    #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	sample
    1	169	.	A	T	96	PASS	.	GT	1/1
    <BLANKLINE>

Mutate is smart enough not to overlay multiple variants. Consider the following parameter file that generates SNPs
uniformly across the sequence

    >>> json.dump(
    ... {
    ...      "input smalla file": "README-DATA/porcine_circovirus_0.smalla",
    ...      "output vcf file": "README-DATA/variants.vcf",
    ...      "chromosome": "1",
    ...      "mutations": {
    ...          "snp": {
    ...              "model": "snp",
    ...              "start_snps_frac": 0.0,
    ...              "stop_snps_frac":  1.0,
    ...              "phet": 0.0,
    ...              "p": 0.01,
    ...              "poisson_rng_seed": 1,
    ...              "base_sub_rng_seed": 2
    ...          }
    ...      }
    ...  }, open('README-DATA/mutations2.json','w'), indent=2)

(Note that you can leave out parameters. In general, programs in Mitty will fill out missing parameters with defaults. In
this case we left out the `het_rng_seed` but `phet=0.0` means that we don't need that anyway.)

Let's take a look at the resulting VCF file:

    >>> shell('python mutate.py --paramfile=README-DATA/mutations2.json')
    >>> with open('README-DATA/variants.vcf','r') as f: print f.read()  # doctest: +ELLIPSIS, +NORMALIZE_WHITESPACE
    ##fileformat=VCFv4.1
    ##fileDate=...
    ##source=...
    ##reference=porcine_circovirus_0.smalla
    #CHROM  POS     ID      REF     ALT     QUAL    FILTER  INFO    FORMAT  sample
    1       99      .       C       G       96      PASS    .       GT      1/1
    1       187     .       A       C       96      PASS    .       GT      1/1
    1       277     .       T       C       96      PASS    .       GT      1/1
    1       374     .       T       A       96      PASS    .       GT      1/1
    1       472     .       T       A       96      PASS    .       GT      1/1
    1       570     .       T       C       96      PASS    .       GT      1/1
    1       657     .       A       G       96      PASS    .       GT      1/1
    <BLANKLINE>

Consider the following parameter file that generates deletes uniformly across the sequence


    >>> json.dump(
    ... {
    ...      "input smalla file": "README-DATA/porcine_circovirus_0.smalla",
    ...      "output vcf file": "README-DATA/variants.vcf",
    ...      "chromosome": "1",
    ...      "mutations": {
    ...          "delete": {
    ...              "model": "delete",
    ...              "start_dels_frac": 0.0,
    ...              "stop_dels_frac":  1.0,
    ...              "phet": 0.0,
    ...              "p_del": 0.01,
    ...              "lam_del": 10,
    ...              "del_loc_rng_seed": 3,
    ...              "del_len_sub_rng_seed": 4
    ...          }
    ...      }
    ...  }, open('README-DATA/mutations3.json','w'), indent=2)

Let's take a look at the resulting VCF file:

    >>> shell('python mutate.py --paramfile=README-DATA/mutations3.json')
    >>> with open('README-DATA/variants.vcf','r') as f: print f.read()  # doctest: +ELLIPSIS, +NORMALIZE_WHITESPACE
    ##fileformat=VCFv4.1
    ##fileDate=...
    ##source=...
    ##reference=porcine_circovirus_0.smalla
    #CHROM  POS     ID      REF     ALT     QUAL    FILTER  INFO    FORMAT  sample
    1       102     .       CCGTTACCGC      C       96      PASS    .       GT      1/1
    1       196     .       TCCTGGG T       96      PASS    .       GT      1/1
    1       283     .       TACTACAG        T       96      PASS    .       GT      1/1
    1       361     .       AGTGCTGTTA      A       96      PASS    .       GT      1/1
    1       465     .       CTACCACTCC      C       96      PASS    .       GT      1/1
    1       570     .       TGGAAATGTA      T       96      PASS    .       GT      1/1
    1       663     .       CAGAGAA C       96      PASS    .       GT      1/1
    <BLANKLINE>

If we put these two sets of mutations together, we can see that the SNP at 374 would overlap with the delete starting at
361 and the SNP at 472 would come right after the delete at 465. The SNP at 570 would come right before the delete at
570. For purposes of clarity (see below) we like to have at least a one base gap between mutations.

When we ask `mutate.py` for both these sets of mutations (keeping the same random seeds),

    >>> json.dump(
    ... {
    ...      "input smalla file": "README-DATA/porcine_circovirus_0.smalla",
    ...      "output vcf file": "README-DATA/variants.vcf",
    ...      "chromosome": "1",
    ...      "mutations": {
    ...          "snp": {
    ...              "model": "snp",
    ...              "start_snps_frac": 0.0,
    ...              "stop_snps_frac":  1.0,
    ...              "phet": 0.0,
    ...              "p": 0.01,
    ...              "poisson_rng_seed": 1,
    ...              "base_sub_rng_seed": 2
    ...          },
    ...          "delete": {
    ...              "model": "delete",
    ...              "start_dels_frac": 0.0,
    ...              "stop_dels_frac":  1.0,
    ...              "phet": 0.0,
    ...              "p_del": 0.01,
    ...              "lam_del": 10,
    ...              "del_loc_rng_seed": 3,
    ...              "del_len_sub_rng_seed": 4
    ...          }
    ...      }
    ...  }, open('README-DATA/mutations4.json','w'), indent=2)

we get:

    >>> shell('python mutate.py --paramfile=README-DATA/mutations4.json')
    >>> with open('README-DATA/variants.vcf','r') as f: print f.read()  # doctest: +ELLIPSIS, +NORMALIZE_WHITESPACE
    ##fileformat=VCFv4.1
    ##fileDate=...
    ##source=...
    ##reference=porcine_circovirus_0.smalla
    #CHROM  POS     ID      REF     ALT     QUAL    FILTER  INFO    FORMAT  sample
    1       99      .       C       G       96      PASS    .       GT      1/1
    1       102     .       CCGTTACCGC      C       96      PASS    .       GT      1/1
    1       187     .       A       C       96      PASS    .       GT      1/1
    1       196     .       TCCTGGG T       96      PASS    .       GT      1/1
    1       277     .       T       C       96      PASS    .       GT      1/1
    1       283     .       TACTACAG        T       96      PASS    .       GT      1/1
    1       361     .       AGTGCTGTTA      A       96      PASS    .       GT      1/1
    1       374     .       T       A       96      PASS    .       GT      1/1
    1       465     .       CTACCACTCC      C       96      PASS    .       GT      1/1
    1       570     .       T       C       96      PASS    .       GT      1/1
    1       657     .       A       G       96      PASS    .       GT      1/1
    1       663     .       CAGAGAA C       96      PASS    .       GT      1/1


Mutate resolves the conflicts between the mutations and ensures they don't clash.

Also note that we've kept all our random number generators independent. This allows us greater control over the data
we generate and allows us to avoid unexpected interactions between all our variables.

Generating reads
================

In the previous section we learned how to use `mutate.py` to generate a VCF file with simulated variants representing
a mutated sequence. We would, eventually, like to simulate reads from this mutated sequence. This is a two step process.
In the first step we use `vcf2seq.py` to write out the mutated sequence by combining the reference sequence with the
VCF file. `vcf2seq.py` also writes out a `pos` (position) file. In the next step we invoke `reads.py` to actually
generate the reads. Just like `mutate.py` has different variant generating models `reads.py` has different read generating
models simulating the read characteristics of different machines. **For every read we generate we store POS and CIGAR
strings that correspond to a perfect alignment. We can use this to diagnose performance and errors in aligners and
variant callers**. The POS and CIGAR are written into the qname field of the read and are easily extracted. The simple
program `cheata.py` will generate a perfect alignment for you from a simulated .bam file produced by `reads.py`


vcf2seq
-------
Running vcf2seq will generate a mutated sequence and a `.pos` file that contains important indexing information used by
`reads.py`.

    >>> shell('python vcf2seq.py README-DATA/porcine_circovirus_0.smalla README-DATA/pc_mutated 1 README-DATA/variants.vcf.gz  --ploidy=2')

This generates two sequences `pc_mutated_0.smalla` and  having all the mutations described in the VCF file above. Using
a pen and paper we can work out what the mutated sequence should look like:

                                                                                                    C -> G                                                                                  A -> C                                                                                    T -> C                                                                                                                                                                                                                                                                                               T -> C                                                                                 A -> G
                                                                                                      |                                                                                       |                                                                                         |                                                                                                                                                                                                                                                                                                    |                                                                                      |
    ATGACGTATCCAAGGAGGCGTTACCGGAGAAGAAGACACCGCCCCCGCAGCCATCTTGGCCAGATCCTCCGCCGCCGCCCCTGGCTCGTCCACCCCCGCCACCGTTACCGCTGGAGAAGGAAAAACGGCATCTTCAACACCCGCCTCTCCCGCACCTTCGGATATACTATCAAGCGAACCACAGTCAAAACGCCCTCCTGGGCGGTGGACATGATGAGATTCAATATTAATGACTTTCTTCCCCCAGGAGGGGGCTCAAACCCCCGCTCTGTGCCCTTTGAATACTACAGAATAAGAAAGGTTAAGGTTGAATTCTGGCCCTGCTCCCCGATCACCCAGGGTGACAGGGGAGTGGGCTCCAGTGCTGTTATTCTAGATGATAACTTTGTAACAAAGGCCACAGCCCTCACCTATGACCCCTATGTAAACTACTCCTCCCGCCATACCATAACCCAGCCCTTCTCCTACCACTCCCGCTACTTTACCCCCAAACCTGTCCTAGATTCCACTATTGATTACTTCCAACCAAACAACAAAAGAAATCAGCTGTGGCTGAGACTACAAACTGCTGGAAATGTAGACCACGTAGGCCTCGGCACTGCGTTCGAAAACAGTATATACGACCAGGAATACAATATCCGTGTAACCATGTATGTACAATTCAGAGAATTTAATCTTAAAGACCCCCCACTTAACCCTTAG
                                                                                                          ------------                                                                                  ---------------------                                                                  -------                                                                       -------------                                                                                           ------                                                                                                                                                                                                -----------
                                                                                                              del                                                                                                del                                                                             del                                                                              del                                                                                                  del                                                                                                                                                                                                     del

    --> work this out again

and compare it to the generated one

    >>> with open('README-DATA/pc_mutated_0.smalla','r') as f: print f.read()
    ATGACGTATCCAAGGAGGCGTTACCGGAGAAGAAGACACCGCCCCCGCAGCCATCTTGGCCAGATCCTCCGCCGCCGCCCCTGGCTCGTCCACCCCCGGCACTGGAGAAGGAAAAACGGCATCTTCAACACCCGCCTCTCCCGCACCTTCGGATATACTATCAAGCGAACCACAGTCCAAACGCCCTCGGTGGACATGATGAGATTCAATATTAATGACTTTCTTCCCCCAGGAGGGGGCTCAAACCCCCGCTCTGTGCCCCTTGAATAATAAGAAAGGTTAAGGTTGAATTCTGGCCCTGCTCCCCGATCACCCAGGGTGACAGGGGAGTGGGCTCCATTCAAGATGATAACTTTGTAACAAAGGCCACAGCCCTCACCTATGACCCCTATGTAAACTACTCCTCCCGCCATACCATAACCCAGCCCTTCTCCCGCTACTTTACCCCCAAACCTGTCCTAGATTCCACTATTGATTACTTCCAACCAAACAACAAAAGAAATCAGCTGTGGCTGAGACTACAAACTGCCGGAAATGTAGACCACGTAGGCCTCGGCACTGCGTTCGAAAACAGTATATACGACCAGGAATACAATATCCGTGTAACCATGTATGTGCAATTCTTTAATCTTAAAGACCCCCCACTTAACCCTTAG

reads
-----
We first create a parameter file. Note that we want to simulate reads from a diploid organism and so we pass in two
file names under `input_sequences`. This element (alongwith `total_reads` and `read_ranges`) must always be a list.

    >>> json.dump(
    ... {
    ...     "input_sequences": ["README-DATA/pc_mutated_0.smalla", "README-DATA/pc_mutated_1.smalla"],
    ...     "total_reads": [100, 100],
    ...     "is_this_ref_seq": False,
    ...     "read_ranges": [[0.0, 1.0], [0.0, 1.0]],
    ...     "output_file_prefix": "README-DATA/sim_reads",
    ...     "read_model": "tiled_reads",
    ...     "model_params": {
    ...         "paired": False,
    ...         "read_len": 100,
    ...         "template_len": 250,
    ...         "read_advance": 50
    ...     }
    ... }, open('README-DATA/read_par.json','w'), indent=2)


Now we run `reads.py` with an appropriate read parameter file to generate a bucket of reads.

    >>> shell('python reads.py  --paramfile=README-DATA/read_par.json  --corrupt')

This produces a BAM file (`sim_reads.bam`) with perfect reads from the mutated sequence. Because of the `--corrupt` option it
also produces `sim_reads_c.bam` which has corrupted reads. This uses the stock plugin which generates errors at the
inner ends of the reads with an exponential envelope.

Note that if we wanted to generate reads from a reference sequence we would simply feed `reads.py` with the sequence.

cheata
------
We can run `cheata.py`on this BAM file to generate perfect alignment

    >>> shell('python cheata.py --inbam=README-DATA/sim_reads.bam --outbam=README-DATA/aligned.bam  --heada=README-DATA/porcine_circovirus_0.smalla.heada')

Now you can use `samtools tview` or `tablet` or `IGV` to open up `aligned.bam` and see the perfectly aligned assembly of
the data.

You can repeat the process with the corrupted reads to get a perfectly aligned BAM but with simulated corruption in the
reads.

    >>> shell('python cheata.py --inbam=README-DATA/sim_reads_c.bam --outbam=README-DATA/aligned_c.bam  --heada=README-DATA/porcine_circovirus_0.smalla.heada')


Testing `samtools mpileup`
=========================
Having done these steps, we can now test the `samtools mpileup` function and see if we can find back the variants we
put into the mutated sequence from which we just generated reads.

We first run `mpileup` on the perfect alignment

    >>> shelly('samtools mpileup -uf Data/porcine_circovirus.fa README-DATA/aligned.bam | bcftools view -bvcg - > README-DATA/var.raw.bcf')
    >>> shelly('bcftools view README-DATA/var.raw.bcf | vcfutils.pl varFilter -D100 > README-DATA/mpileup.vcf')

Then we compare the original VCF with  the detected one

    >>> shell('tail -n -11 README-DATA/variants.vcf')
    >>> shell('tail -n -11 README-DATA/mpileup.vcf')

The VCF entries should indicate identical variants from the `mpileup` command as we generated in the simulation.


Testing BWA alignment
=====================
How about using `reads.py` to generate some reads from a reference sequence and then checking how well a commonly used
aligner can align the reads?

    >>> shell('python converta.py Data/adenovirus.fa README-DATA/adenovirus')
    >>> json.dump(
    ... {
    ...     "input_sequences": ["README-DATA/adenovirus_0.smalla"],
    ...     "coverages": [10.0],
    ...     "is_this_ref_seq": True,
    ...     "read_ranges": [[0.0, 1.0]],
    ...     "output_file_prefix": "README-DATA/adeno_reads",
    ...     "read_model": "simple_reads",
    ...     "model_params": {
    ...         "paired": True,
    ...         "read_len": 10,
    ...         "template_len": 250,
    ...     }
    ... }, open('README-DATA/adeno_read_par.json','w'), indent=2)
    >>> shell('python reads.py  --paramfile=README-DATA/adeno_read_par.json')
    >>> shelly('samtools bam2fq README-DATA/adeno_reads.bam > README-DATA/raw_reads.fq')
    >>> shell('bwa index Data/adenovirus.fa')
    >>> shelly('bwa mem -p Data/adenovirus.fa README-DATA/raw_reads.fq > README-DATA/adeno_aligned.sam')
    >>> shelly('samtools view -Sb README-DATA/adeno_aligned.sam > README-DATA/temp.bam')
    >>> shell('samtools sort README-DATA/temp.bam README-DATA/adeno_aligned')
    >>> shell('samtools index README-DATA/adeno_aligned.bam')
    >>> shell('python cheata.py split --inbam=README-DATA/adeno_aligned.bam')
    >>> shell('python Analysis/diagnose_alignment.py --correctbam=README-DATA/adeno_aligned_correct.bam --wrongbam=README-DATA/adeno_aligned_wrong.bam  --smalla=README-DATA/adenovirus_0.smalla  --outpkl=README-DATA/bwa_adenovirus_stats.pkl  --outfig=README-DATA/bwa_adenovirus_stats.png')

You should end up with a page of plots telling you how well the aligner did its job

![Aligner summary figure]: (README-DATA/bwa_adenovirus_stats.png)


For further examples of what Mitty can do for you, please refer to the `Examples` directory and the `Readme.md`
file there to read along. For each of the programs listed above please run the `-h` option to learn the usage pattern.


Installation
============

There are two branches in the repository:

    master - stable working code
    dev    - code could be unstable/unworking but will have the latest experimental stuff going on

The code requires the following non-standard modules

    BioPython   - pip install biopython --user
    PyVCF       - pip install pyvcf --user
    pysam       - pip install pysam -- user

The code requires the following external tools to run the examples

    bgzip       - to compress VCF file
    tabix       - to index VCF file
    samtools    - indexing fasta and converting between bam and sam etc
    bwa         - alignments etc.



Subdirectories
--------------
    Params      - example parameter files for mutate.py and reads.py
    Recipes     - snippets of code (shell scripts and python scripts) to do/show particular tasks. useful for devs and
                  users alike
    Data        - test data for the programs
    Plugins     - directory where simulation models are stored


Files and formats
-----------------

## VCF

`vcf2seq.py` currently handles a specific interpretation of the VCF. In the most liberal interpretation of the VCF the
REF sequence corresponds to bases matching the reference starting at POS and those bases are replaced by the bases found
in ALT. Any number of bases in ALT may match the REF in any place (though this is not very useful to us).

Mitty has a more strict interpretation of the VCF. In Mitty's interpretation, at most, the first base
of REF will match with ALT. All other bases must be different. All variants can be coded in this manner:

Say our original sequence is `ATCGGATC`

                 POS   REF     ALT
    Deletion      1   ATCG     A     -> AGATC
    Deletion      2   TCG      .     -> AGATC     (Though this form is interpreted by vcf2seq it is never produced by mutate.py)
    Deletion      1    A       .     -> TCGGATC
    Insertion     0    .      TTT    -> TTTATCGGATC
    Insertion     1    A      AGGG   -> AGGGTCGGATC
    SNP           1    A       G     -> GTCGATC

In addition to this Mitty adds an additional code to the genotype (GT) field 1/0. This is because in the simulation we
have actual access to which copy of a diploid sequence has a heterozygous mutation. Therefore we use the GT field to
encode on which set of the sequence the variant exists. Note that VCF files produced by Mitty never have 0/0 as we do
not include any standard variant from a library.

## "Buffer bases" between simulated variants

If we have variants adjacent to each other the most parsimonious description of the resulting variation can be different
from the original variants.

For example, considering `M=ATCGATCG` and an insertion and deletion as follows

    POS REF ALT
    1   A   ACC
    1   AT  A

We get

         1  2345678
    R    A  TCGATCG
    M    ACC CGATCG

This can, actually, be most parsimoniously expressed as

         1 2345678
    R    A TCGATCG
    M    ACCCGATCG

Which is a single base insertion followed by a SNP

    POS REF ALT
    1   A  AC
    2   T  C

For reasons of such ambiguity Mitty places a minimum 1 base "buffer" between variants, making the generated variant
identical to the most parsimonious description.


Dev notes
=========

Plugin system for simulation models
-----------------------------------

Mitty implements models for variant and read simulation as Python modules located in the Plugins directory. The modules
need to expose a few key functions that `mutate.py` and `reads.py` use to determine variant and read characteristics.
Mitty infers the module name from the name given in the parameter .json file. Mitty comes with some stock models for
variant and read simulation which can be used as example code.

### Random number generators, blocked computation etc.
You will note that the stock plugins accept one or more inputs that serve as seeds for internal random number
generators. These seeds need to be specified in the simulation parameter files and ensure reproducibility of
simulations.

Some of the models use several, independently seeded, random number generators for different variables (e.g.
insertion length and insertion position) to avoid unexpected interactions between such simulated variables. The
algorithms are also designed such that the simulation results are independent of block size.


Algorithms
----------
### Variants, reads and CIGARS
One big goal of Mitty is to serve up realistic test data for bioinformatics algorithms, from aligners to variant
callers. Testing whether a variant caller is correctly working on the simulated data is relatively easy: we simply
compare the variant caller's VCF file with the answer book VCF generated by Mitty. It is, however, slightly more involved
to deduce if an aligner is correctly aligning the simulated reads, and to diagnose how the performance of an aligner is
affecting the accuracy of a variant caller. To this end Mitty has a system to compute the correct read position and
CIGAR for each simulated read. This information is stored in the read's qname string so that it is easily accessible
to diagnostic programs.

In order to generate reads based on a given VCF file and a reference sequence we go through a two step process.
We first generate the mutated sequence (`mut_seq`) along with some other information that encodes the difference between
each base in the `mut_seq` and corresponding positions on the `ref_seq`. We then generate reads from the `mut_seq` using
the sidecar information to compute the correct POS values and CIGAR strings for the reads.

The algorithm is best introduced through a series of examples. In the examples the reference sequence is labelled `R` and
the mutated sequence is labeled `M`. The information for setting the POS and CIGAR for the read is taken from an
array `pos` that accompanies `M`

#### Generating `pos`

Let `R = ACTGACTG`

Consider a single base insertion at position 1

    POS REF ALT
    1   A   AT

         1 2345678
    R    A CTGACTG
    M    ATCTGACTG
    pos  1223456789


Consider a multiple base insertion at position 1

    POS REF ALT
    1   A   ATT

         1  2345678
    R    A  CTGACTG
    M    ATTCTGACTG
    pos  12223456789


Consider a multiple base insertion at last position

    POS REF ALT
    8   G   GTT

         12345678
    R    ACTGACTG
    M    ACTGACTGTT
    pos  12345678999

Consider a multiple base deletion

    POS REF ALT
    2   CTG  C

         12345678
    R    ACTGACTG
    M    AC  ACTG
    pos  12  56789

Consider a SNP, an insertion and a deletion

    POS REF ALT
    2   C   T
    4   G   GTT
    6   CTG C

         1234  5678
    R    ACTG  ACTG
    M    ATTGTTAC
    pos  123455569


`pos` is generated by copying over the index from `R`. When we encounter an insertion we copy over the index of the next
reference base as many times as there is an insertion. Deletions are simply skipped. For the purposes of computing `pos`
we also add an imaginary base position at the end of the reference sequence (9 in this case)

You can "read along" to these examples by running `python vcf2seq.py test -v` and seeing how different functions in
`vcf2seq.py` implement these algorithms

#### Generating CIGARS and POS for reads from `pos`
Consider our last example and some reads from `M`

         1234  5678
    R    ACTG  ACTG
    M    ATTGTTAC
    pos  123455569
         ++++---------> POS = 1 (The first pos value we encounter)
                        CIGAR = 4M  (2-1=1 -> 1M
                                     3-2=1 -> 1M
                                     4-3=1 -> 1M
                                     5-4=1 -> 1M)

    M    ATTGTTAC
    pos  123455569
          ++++--------> POS = 2 (The first pos value we encounter)
                        CIGAR = 3M1I  (3-2=1 -> 1M
                                       4-3=1 -> 1M
                                       5-4=1 -> 1M
                                       5-5=0 -> 1I)

    M    ATTGTTAC
    pos  123455569
           ++++-------> POS = 3
                        CIGAR = 2M2I  (4-3=1 -> 1M
                                       5-4=1 -> 1M
                                       5-5=0 -> 1I
                                       5-5=0 -> 1I)

    M    ATTGTTAC
    pos  123455569
             ++++-----> POS = 5
                        CIGAR = 2I2M  (5-5=0 -> 1I
                                       5-5=0 -> 1I
                                       6-5=1 -> 1M
                                       9-6=3 -> 1M + 2D) The D only comes into play if our read crosses the deletion

To see how a deletion affects our POS and CIGAR consider another previous example

    POS REF ALT
    2   CTG  C

         12345678
    R    ACTGACTG
    M    AC  ACTG
    pos  12  56789
         ++  ++-------> POS = 1
                        CIGAR = 2M2D2M  (2-1=1 -> 1M
                                         5-2=3 -> 1M + 2D The 2D comes into play because the read crosses the boundary
                                         6-5=1 -> 1M
                                         7-6=1 -> 1M)

Example of an unmapped read

    POS REF ALT
    2   C  CAATTGG

         12      345678
    R    AC      TGACTG
    M    ACAATTGGTGACTG
    pos  123333333456789
           ++++-------> POS = 3
                        CIGAR = 4I  (3-3=0 -> 1I
                                     3-3=0 -> 1I
                                     3-3=0 -> 1I
                                     3-3=0 -> 1I)
    For a read to be mapped, there has to be at least one M. Since there are no Ms we discard the POS and CIGAR as this
    is an unmapped read

`reads.py` generates simulated reads from `mut_seq` based on the read model. Using the `pos` arrays it
also generates appropriate alignment information (POS and CIGAR) that is stored in the qname string.
(Note that while the BAM specs do not place a limit on the length of the qname string both Tablet and IGV expect a
string with length < 255 characters. It is possible that the qname will exceed this and you won't be able to open a
set of simulated reads using tools that arbitrarily limit the qname). If no `pos` file is supplied `reads.py` assumes
we are taking reads from a reference sequence and the POS values are actual positions of the reads and all the cigars
are of the form `100M` (For e.g. 100 base reads).

Computing POS: For every read, the POS value is simply the index from `pos` corresponding to the first base of the read
EXCEPT for unmapped reads.

Computing the CIGAR:

1. Initialize the base counter to `None`, set mapped flag to `False`
2. Step through the each base of the read and look at the difference in `pos` values `dp`
3. If `dp==1`, if the counter is any thing other than `M`, flush it. Set or increment counter as `M`. Set mapped flag to `True`
4. If `dp==0`, if the counter is other than `I`, flush it. Set or increment counter as `I`
5. If `dp>1`, if the counter is other than `M`, flush it. Set and flush counter as `M`, set counter as `D` to be dp-1
6. Continue from 2 until done.
7. Flush any counter other than `D`
8. If the mapped flag is `False` reset POS and CIGAR - this is an unmapped read.

You can "read along" to these examples by running `python reads.py test -v` and seeing how different functions in
`reads.py` implement these algorithms


Misc design choices
===================

HDF5 for Whole genome file
--------------------------




I went from complete block processing of reading fasta files to reading in whole sequences. This is because for our use
case (Human) the individual chromosomes are small enough to fit even on modest machines.


### Choice to output a mutated sequence as a whole
Though generating a whole mutated sequence uses a lot of disk space, I chose this approach as it ended up being simpler
than coming up with an algorithm for generating reads on the fly based ona  VCF file. In the future the code may be
converted to do on the fly generation.

### Parameter files for mutate
1. I chose to use parameter files because we often want to rerun experiments and it became clear early on that there would
be a lot of parameters.
1. I chose to use python for the parameter file for parsimony and flexibility
1. The parameter distribution between file and command line was based on predictions of which parameters we could
experiment with most during testing
1. At this time I do not know whether having everything on the commandline would be better for PIPITOR or if param files
are preferred for Platform integration, but either way is a short code reorganization that can be done quickly at the
time of integration.

### POS files
These are simple binary files carrying unsigned 4 byte int information. This is enough to handle index/index diff sizes
for human genome sizes, though if we ever work on heavily mutated specimens of the loblolly pine, perhaps we have to
go to 8 byte ints ...




Python's native mmap can't do proper offsets ... should we use numpy?



Notes:
======

Sequence data
-------------
Sequence data used as examples are from the NIH:

1. `porcine_circovirus.fa` [porcine circovirus sequence][porcine] (702 b)
1. `altered_porcine.fa` taken from above but with 'N's and lowercase bases inserted to test converters
1. `adenovirus.fa` [Porcine adenovirus 3 DNA, complete genome][adeno] (34094 b))
1. `herpes.fa` [Human herpes virus 1 GenBank: KC140233.1][herpes] (717 b)
1. `parvovirus.fa` [Parvovirus H1, complete genome NC_001358.1][parvovirus]


[porcine]: http://www.ncbi.nlm.nih.gov/nuccore/AY735451.1
[adeno]: http://www.ncbi.nlm.nih.gov/nuccore/AB026117.1
[herpes]: http://www.ncbi.nlm.nih.gov/nuccore/448872318
[parvovirus]: http://www.ncbi.nlm.nih.gov/nuccore/NC_001358.1




tmat = """
0.32654629,  0.17292732,  0.24524503,  0.25528135
0.3489394,   0.25942695,  0.04942584,  0.3422078
0.28778188,  0.21087004,  0.25963262,  0.24171546
0.21644706,  0.20588717,  0.24978216,  0.32788362"""

[[float(col) for col in row.split(',')] for row in tmat.strip().split('\n')]
