This directory contains wrapper code that allows Mitty components to run on the Seven Bridges Platform. Instructions
for wrapping are found here and might be helpful to devs.

Setting up, directory structure etc. etc.
----------
_I don't understand docker/VM/vagrant internals. My user's view of what we are doing as we write wrappers for
our tools and then upload these wrappers to the Seven Bridges computing platform is set out as annotations in
this recipe book. They will probably be wrong, please tell me so I can correct the statements._

**Please read the initial part of the [SBG pipeline documentation][sbgreadme] to see how to install Vagrant and
VirtualBox.**

_The SBG readme takes your through the steps of setting up your own project. Here I will concentrate on how to setup
with Mitty to do your own development. This will closely follow the general use case where you have some code that
you want to wrap for the Seven Bridges Platform, but you might not need to be as particular with your directory layout
(and can simply follow the instructions in the SBG readme)_

[sbgreadme]: http://pythonhosted.org/sbgsdk/tutorial.html

_Most of the tips and tricks in this readme are due to Nebojsa Tijanic of Seven Bridges_


### Where to put what: Setting up the SBG virtual machine for convenient development
The typical use case we follow is where the tools you are trying to wrap have been "frozen" and you are testing and
debugging wrappers to use the tools on the platform. In my workflow I like to include the wrapper code as part of my
main tool repository. My main code repository is `Mitty` with the wrappers for the Seven Bridges platform kept under a
directory called `SbgWrappers`

    /Users/kghose/Code
    |
    |______ Mitty
    | |______ (Tool related directories)
    | |______ SbgWrappers
    | | |______ .sbdk

The `.sbdk` directory contains three `.json` configuration files:

    logging.json     - some configuration for the sbg platform's logging tools. I leave these along.
    schema.json      - autogenerated (and overwritten) by the sbg tools
    state.json       - contains image_id and project_name. Will be important later

The download archive from SBG contains `Vargrantfile`, which has information about the virtual machine base image
supplied by SBG. I simply copy `Vagrantfile` to `/Users/kghose/Code/Vagrantfile` (more on why later)

    /Users/kghose/Code
    |
    |______ Mitty
    | |______ (Tool related directories)
    | |______ SbgWrappers
    | | |______ .sbdk
    |______ Vagrantfile

Now, if we go under `Code`, we can tell Vagrant to pull the image and setup SBGs Linux VM development environment.

    cd /Users/kghose/Code
    vagrant up

This starts a Linux virtual machine whose state is stored in a newly created `.vagrant` directory.
Also note that the log information that Vagrant puts out indicates that (for example in my case) the virtual machine
folders are mapped to the outside.

    /vagrant => /Users/kghose/Code
    /home/vagrant/projects => /Users/kghose/Code

We can now log into the VM while sitting at `/Users/kghose/Code`. While inside this virtual machine you should be able
to see all the directories at the same level as `Code` such that
`ls projects` and `ls /vagrant` should both show you those file/directories. This is the "trick" (proper placement of
the Vargant file) that allows us to now access our wrapper code under `projects/Mitty/SbgWrappers/`. This way we can
work on the wrapper code from our dev machine and have the changes visible to the SBG Linux VM and not have to mess with
pushing and pulling wrapper code.

Log in to this virtual machine and pull the docker image.

    vagrant ssh                         # Start an ssh session with the guest machine.
    ls projects/                        # You should see all the files/directories at same level as Vagrant file

    # Currently, you have to manually pull the SBG beta container though this is supposed to automatically happen
    # this is the magic sauce to get us started.
    docker pull sevenbridges/sdkbase:beta

### Enter a container and setup the environment

**This next step is important** The `image_id` in `.sbdk/state.json` is the image id of whatever machine I used for
development. This needs do be updated with the image id of the actual docker image we are on now

    docker images  # Find the image id and replace it in the appropriate place in .sbdk/state.json

You don't need to do this if you are starting a project from scratch. In that case you should do `sbg init` which will
create the `.sbdk` and fill out the `state.json` for you and

    cd projects/Mitty/SbgWrappers/mitty
    sbg sh  # This command will only run when called from a directory at the level of or under the .sbdk folder

This puts you in a docker container where you will set up your tools and any environment (packages, variables, paths)
that your tool needs.

**Interestingly, any `sbg` command other than `sbg sh` seems to require an internet connection. This includes sbg test.
I'm not sure why. This puts a mild damper on things, since I often write code on the train etc. where I don't have an
internet connection.**

For Mitty I do the following things

    sudo pip install sbgsdk --upgrade   # Make sure we have the latest SDK.

    # Now, install the dependencies that Mitty needs that is not included with the sbg image. This will take a while.
    pip install docopts pysam pyvcf numpy

    # We need to have git to pull our code
    apt-get update
    apt-get install git

### Pull your tools
You can put your tools anywhere, I just put them at the root directory. Just make sure your wrappers know the path to
the executable or have the path in your environment.

    cd /   #I put my tools at the root. This is reflected in the wrapper code
    git clone https://github.com/latticelabs/Mitty.git  # Pull the code
    exit  # Exit from the container.

**Don't forget to hit 'y' when asked whether you want to commit the changes, otherwise the container will not be
updated and your changes will be lost**

If you need to update the tool code, simply do a git pull from now on.

    sbg sh
    cd /Mitty
    git pull
    exit  # Say yes to committing changes

### Wrappers
Now, because of where we placed everything, the wrapper code, which sits at `/Users/kghose/Code/Mitty/SbgWrappers` is
visible from the VM under `projects/Mitty/SbgWrappers/`.

You can now test some of the wrappers if you are logged into the VM:

    sbg test mitty.mutation_wrapper
    sbg test mitty.reads_wrapper

An interesting command to run from within a container is TODO: Check if we need to be in a container for this.

    sbg schema

This reads the wrappers listed in `__init__.py` and drops json output that looks like:

      {
        "schema": {
          "inputs": [],
          "outputs": [
            {
              "description": "Deletion definitions for mutate",
              "id": "json_fragment",
              "list": false,
              "name": "Deletions",
              "required": false,
              "types": []
            }
          ],
          "params": [
            {
              "category": "General",
              "condition": null,
              "default": null,
              "description": "A unique name for this instance of the insert generator",
              "id": "model_id",
              "list": false,
              "name": "Model id",
              "pattern": null,

                  ...

              "required": false,
              "step": null,
              "type": "integer"
            }
          ]
        },
        "wrapper_id": "mitty.plugins.mutation.delete_wrapper.Deletion"
      }

Writing a wrapper
-----------------
Writing wrappers is a bit of an art, and there is no one unique way to wrap any but the simplest tool. We will follow
along using a rather complete example `mutate_wrapper.py` and an auxiliary wrapper `plugins.mutation.snp_wrapper.py`.

`mutate_wrapper.py` wraps the tool  `mutate.py`. `mutate.py` is driven by a set of command line arguments, takes in a
data file as input, another text file as a parameter set and produces three files as output.  An important consideration
for this tool is that the format of the parameter file is not fixed: the tool takes in plugins to work and each plugin
has a different set of parameters.

Conceptually, the plugins feed into `mutate` giving it information about how to do its job. What we end up doing is
creating a set of auxiliary plugin wrappers corresponding to all the plugins. None of these wrappers process
any data files or call any external tools. Instead what they do is take in the parameters required by the respective
plugins and convert them to file fragments. These file fragments are then combined together by `mutate_wrapper` to
form a complete input parameter file used to drive `mutate`.

Importantly, structuring the wrappers in this manner allows us to represent the plugins as nodes feeding into mutate
which matches with the conceptual design.

```Python
"""This wrapper only translates input parameters into a json file that is an input to the mutate wrapper. The mutate
wrapper combines json fragments from all the plugins into a complete json parameters file that is then fed to mutate.py

The .json fragment should look like
          ______________ model id
        /
      "snp": {
          "model": "snp",
          "start_snps_frac": 0.1,
          "stop_snps_frac":  0.3,
          "phet": 0.5,
          "p": 0.01,
          "het_rng_seed":3,
          "strand_rng_seed": 4,
          "poisson_rng_seed": 1,
          "base_sub_rng_seed": 2
      }

mutate_wrapper will place this snippet under "mutations"
"""
import os
import json
```

The package sbgsdk contains methods/definitions/classes that we inherit from to create the wrappers

```Python
from sbgsdk import define
from nose.tools import assert_equals
```
###Inputs and Outputs
We can leave out Class Inputs altogether, since we don't have any inputs. We'll see in ``mutate_wrapper` how do deal with
a variety of inputs.

```Python
class SNP(define.Wrapper):
  class Inputs(define.Inputs):
    pass
```

This is how we indicate a simple output that consists of just one file. In all cases that you will, see the `description`
tag is what is shown in PIPITOR when you hover the mouse over an input or output "pin" for a node. The node name can
be given as `name`, but if you don't, PIPITOR intelligently creates a name from the name of the variable you assign. In
this case, if we didn't give the name, it would appear as `Json Fragment`.

```Python
  class Outputs(define.Outputs):
    json_fragment = define.output(name="SNPs", description="SNP definitions for mutate")
```
###Parameters
Parameters come in many shapes and sizes

    string
    real
    integer
    boolean

We tell the wrapper we are expecting a parameter by using the `define` module. Each definition includes the following
properties

    default
    min, max  - valid for numerical types
    required
    description
    category  - PIPITOR groups parameters under headings based on what you write here

Using these basic types and their properties we can define parameters that will show up on PIPITOR with the relevant
tooltips and names.

```Python
  class Params(define.Params):
    model_id = define.string(required=True, description='A unique name for this instance of the SNP generator',
                             category='General')
    # "snp" in the example above. Needs to be unique
    start_snps_frac = define.real(default=0, min=0, max=1, category='Model params',
                                  description='start generating snps from here (0.0, 1.0)')
    stop_snps_frac = define.real(default=1, min=0, max=1, category='Model params',
                                 description='stop generating snps after this (0.0, 1.0)')
    phet = define.real(default=0.01, min=0, max=1, category='Model params',
                       description='probability of having heterozygous mutation')
    p = define.real(default=0.01, min=0, max=1, category='Model params',
                    description='probability of SNPs')
    het_rng_seed = define.integer(default=1, min=0, max=2**32 - 1, category='Model params: RNG',
          description='Seed for random number generator used to decide if genotype is heterozygous or not')
    strand_rng_seed = define.integer(default=1, min=0, max=2**32 - 1, category='Model params: RNG',
          description='Seed for random number generator used to decide which strand the SNP will be on')
    poisson_rng_seed = define.integer(default=1, min=0, max=2**32 - 1, category='Model params: RNG',
          description='Seed for SNP locator random number generator')
    base_sub_rng_seed = define.integer(default=1, min=0, max=2**32 - 1, category='Model params: RNG',
          description='Seed for random number generator used to select ALT bases')
```

Interestingly, the `.__json__()` method takes the internal dictionary `params.__dict__` and spits out another dictionary
leaving out internal attributes (anything starting with "_" ) and undefined attributes. We use this to generate our parameter
file snippet. Because Mitty parameter files are `.json` formatted this code and we have matched our variable names,
is quite short :)

```Python
  def write_to_json(self, fname):
    with open(fname, 'w') as f:
      params = self.params.__json__()
      params.pop('model_id')
      json.dump({self.params.model_id: dict(model='snp', **params)}, f)
```

###The thing that runs
Every wrapper needs an `execute` method. This is what actually gets called by the Seven Bridges Platform for each
App (or graph node in PIPITOR) when a pipeline is run. In the case of the mutate plugin we don't actually process any
data, we simply want to pass a json fragment onto the mutate wrapper so it can incorporate our plugin parameters before
running `mutate.py`.

```Python
  def execute(self):
    output_dir = 'OUTPUT'
    if not os.path.exists(output_dir):
      os.makedirs(output_dir)
    self.outputs.json_fragment = \
      os.path.join(output_dir, '{:s}_snp_plugin_params.json'.format(self.params.model_id))
    # By adding the model_id bit to the name we ensure uniqueness
    self.write_to_json(self.outputs.json_fragment)
    self.outputs.json_fragment.meta = self.outputs.json_fragment.make_metadata(file_type='json')
```

###Write some tests, you'll thank yourself later
These are the tests run (using `nose`) when you call `sbg test`

```Python
def test():
  params = {
    "model_id": "snp_test",
    "start_snps_frac": 0.1,
    "stop_snps_frac": 0.3,
    "phet": 0,
    "p": 0.01,
    "het_rng_seed": 3,
    "strand_rng_seed": 4,
    "poisson_rng_seed": 1,
    "base_sub_rng_seed": 2
  }
  inputs = {}
  wrp = SNP(inputs, params)
  outputs = wrp.test()
  expected = {
    "snp_test": {
      "model": "snp",
      "start_snps_frac": 0.1,
      "stop_snps_frac":  0.3,
      "phet": 0,
      "p": 0.01,
      "het_rng_seed":3,
      "strand_rng_seed": 4,
      "poisson_rng_seed": 1,
      "base_sub_rng_seed": 2
    }
  }
  with open(outputs.json_fragment) as fp:
    assert_equals(json.load(fp), expected)
```

## A more involved example
We will only present fragments of a larger, more involved wrapper `mutate_wrapper.py` here. The full code is available
on the SBG code repository as `Mitty/SbgWrappers/mutate_wrapper.py`

### Multiple inputs on the same pin
Normally, we assign one input to one pin. However, in this case, we can have a variable number of plugins feeding into
mutate. All the plugins are attached to the same input pin by defining it to be a `list`
TOASK: Is the ordering of the list undefined? Have a way to explicitly order this list

```Python
  class Inputs(define.Inputs):
    ref = define.input(name='Reference', description='The reference sequence (.smalla format)')
    plugins = define.input(name='Plugins', description='The mutation plugins', list=True)
```

This creates a plugin with two input pins. `ref` takes one file as input while `plugins` takes a list of files as input

### Calling a tool
In contrast to our light weight plugin wrapper above, this wrapper really needs to call a tool. We use the `Process`
method supplied by the SDK for this. In the execute method we first create the `.json` parameter file `mutate.py`
needs

```Python
  def execute(self):
    input_name = os.path.splitext(os.path.basename(self.inputs.ref))[0]
    output_basename = input_name + '_variants.vcf' if self.params.vcf_file_name == '' else self.params.vcf_file_name
    output_dir = 'OUTPUT'
    if not os.path.exists(output_dir):
      os.makedirs(output_dir)
    output_absolute_path = os.path.join(output_dir, output_basename)
    mutations = {}
    for in_file in self.inputs.plugins:
      mutations.update(json.load(open(in_file, 'r')))

    params_json = {
      "input smalla file": self.inputs.ref,
      "output vcf file": output_absolute_path,
      "chromosome": self.params.chromosome,
      "mutations": mutations
    }
    with open('params.json', 'w') as fp:
      json.dump(params_json, fp, indent=2)
```

We then run `mutate.py` with this .json file as input

```Python
    p = Process('python', '/Mitty/mutate.py', '--paramfile', 'params.json', '-v')
    p.run()
```

### Handling side-car files - a misuse of list
In a lot of bio-informatics work we produce side-car files that are supposed to ride along with our main file. These
include file meta-data, file indexes, sorted versions of files and so on and so forth. Mutate produces a `.vcf` and
uses `tabix` to zip and index it. Currently the pipeline does not handle such side-car files. To get around this we
declare the output to be a list of files

```Python
  class Outputs(define.Outputs):
    vcf = define.output(name='VCF file', description='A VCF file containing a list of simulated variants', list=True)
```

and then add the vcf and index files to the list:

```Python
  def execute(self):

     ...

    p = Process('python', '/Mitty/mutate.py', '--paramfile', 'params.json', '-v')
    p.run()
    # mutate.py produces three files - the .vcf, the gzipped form .vcf.gz and the tabix index .vcf.gz.tbi
    self.outputs.vcf.add_file(output_absolute_path)
    self.outputs.vcf.add_file(output_absolute_path + '.gz')
    self.outputs.vcf.add_file(output_absolute_path + '.gz.tbi')
    self.outputs.vcf.meta = self.inputs.ref.make_metadata(file_type='vcf')
```

Testing
-------
Calling `sbg test mitty.read_wrapper` runs nose tests on the wrapper called `read_wrapper`. You can also run tests by

    cd /sbgenomics
    pip install .  # Don't need to keep doing this
    nosetests mitty.read_wrapper

You will note that this creates a directory like `test_Reads_t27qu7` under which you will find log files like
`process_0.err` and `process_0.out` and any files/directories your tool creates. This directory is created when the
wrapper is run and all output is dumped in here.


Pushing the wrappers onto the platform
--------------------------------------
After you are satisfied with how the wrappers are working you can push them onto the Seven Bridges computing platform

    sbg push "My commit message which will become the name for this release of the Mitty toolkit"

I usually end up doing something like

    sbg push "v0.1.2"

because that's what appears in the Apps panel on the left and I want that to be informative. This command also
generates the `.sbdk/schema.json` file.

**If you get `No wrappers registered (empty __init__.py?). Exiting.` or if some of your wrappers don't show up in the
`Wrappers` tab, then you need to go fill out `__init__.py` at the root level.** For example

    from .mutate_wrapper import Mutate
    from .plugins.mutation.snp_wrapper import SNP
    from .plugins.mutation.insert_wrapper import Insert
    from .plugins.mutation.delete_wrapper import Deletion

This is cool because it allows you to select which wrappers get pushed. ALL the wrappers, regardless of where they are
located need to be filled out here and not in any `__init__.py` located in any sub-directory.

Next, check at this url to see if the image took (replace the path with your username)

    https://images.sbgenomics.com/v1/repositories/kghosesbg/mitty/images